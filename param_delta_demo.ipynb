{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParamΔ: Zero-Cost Post-Training Demo\n",
    "\n",
    "This notebook demonstrates the ParamΔ method for transferring post-training capabilities without additional training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from src.param_delta import ParamDelta\n",
    "from src.visualization import ParamDeltaVisualizer, DeltaAnalyzer\n",
    "from src.evaluation import ParamDeltaEvaluator\n",
    "\n",
    "print(\"ParamΔ implementation loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding ParamΔ\n",
    "\n",
    "The core formula:\n",
    "- **Parameter Delta**: ΔΘ = Θ_post - Θ_base\n",
    "- **Transfer**: Θ'_post = Θ'_base + ΔΘ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic models for demonstration\n",
    "def create_model(seed, size=128):\n",
    "    torch.manual_seed(seed)\n",
    "    return {\n",
    "        \"layer1.weight\": torch.randn(size, size),\n",
    "        \"layer2.weight\": torch.randn(size, size),\n",
    "        \"layer3.weight\": torch.randn(size, size)\n",
    "    }\n",
    "\n",
    "# Create models\n",
    "theta_base = create_model(seed=0)\n",
    "theta_post = create_model(seed=1)\n",
    "theta_base_new = create_model(seed=2)\n",
    "\n",
    "print(f\"Created {len(theta_base)} layer models\")\n",
    "print(f\"Model size: {sum(p.numel() for p in theta_base.values()) * 4 / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Computing Parameter Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ParamDelta\n",
    "param_delta = ParamDelta(device=\"cpu\")\n",
    "\n",
    "# Compute delta: ΔΘ = Θ_post - Θ_base\n",
    "delta = param_delta.calculate_delta(theta_post, theta_base)\n",
    "\n",
    "# Visualize delta norms\n",
    "delta_norms = {k: torch.norm(v).item() for k, v in delta.items()}\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(delta_norms.keys(), delta_norms.values())\n",
    "plt.xlabel('Layer')\n",
    "plt.ylabel('L2 Norm')\n",
    "plt.title('Parameter Delta Norms by Layer')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average delta norm: {np.mean(list(delta_norms.values())):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Applying Delta to New Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Apply delta: Θ'_post = Θ'_base + ΔΘ\ntheta_param_delta = param_delta.apply_delta(theta_base_new, delta)\n\n# Verify the transformation\nprint(\"Verifying ParamΔ formula...\")\nfor key in theta_base.keys():\n    expected = theta_base_new[key] + (theta_post[key] - theta_base[key])\n    actual = theta_param_delta[key]\n    \n    error = torch.norm(expected - actual).item()\n    print(f\"{key}: error = {error:.2e}\")\n\nprint(\"\\nParamΔ formula verified!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploring Scaling Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different scaling factors\n",
    "scales = np.linspace(0, 2, 11)\n",
    "changes = []\n",
    "\n",
    "for scale in scales:\n",
    "    scaled_model = param_delta.apply_delta(theta_base_new, delta, scale=scale)\n",
    "    \n",
    "    # Measure total change from base\n",
    "    total_change = sum(\n",
    "        torch.norm(scaled_model[k] - theta_base_new[k]).item() \n",
    "        for k in theta_base_new\n",
    "    )\n",
    "    changes.append(total_change)\n",
    "\n",
    "# Plot scaling analysis\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(scales, changes, 'o-', linewidth=2, markersize=8)\n",
    "plt.axvline(x=1.0, color='red', linestyle='--', label='α=1.0 (standard)')\n",
    "plt.xlabel('Scaling Factor (α)')\n",
    "plt.ylabel('Total Change from Base Model')\n",
    "plt.title('Effect of Delta Scaling: Θ\\' = Θ\\'_base + α·ΔΘ')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-Delta Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiple specialized models\n",
    "theta_general = create_model(seed=3)  # General instruction model\n",
    "theta_domain = create_model(seed=4)   # Domain-specific model\n",
    "\n",
    "# Compute multiple deltas\n",
    "delta_general = param_delta.calculate_delta(theta_general, theta_base)\n",
    "delta_domain = param_delta.calculate_delta(theta_domain, theta_base)\n",
    "\n",
    "# Test different mixture ratios\n",
    "ratios = [(1.0, 0.0), (0.7, 0.3), (0.5, 0.5), (0.3, 0.7), (0.0, 1.0)]\n",
    "mixture_results = []\n",
    "\n",
    "for alpha, beta in ratios:\n",
    "    # Combine deltas: Θ' = Θ_base + α·ΔΘ_general + β·ΔΘ_domain\n",
    "    deltas = [(delta_general, alpha), (delta_domain, beta)]\n",
    "    combined = param_delta.combine_multiple_deltas(theta_base_new, deltas)\n",
    "    \n",
    "    # Measure characteristics\n",
    "    total_norm = sum(torch.norm(combined[k]).item() for k in combined)\n",
    "    mixture_results.append(total_norm)\n",
    "\n",
    "# Visualize mixture effects\n",
    "plt.figure(figsize=(8, 5))\n",
    "labels = [f\"({a:.1f}, {b:.1f})\" for a, b in ratios]\n",
    "plt.bar(labels, mixture_results, color=plt.cm.viridis(np.linspace(0, 1, len(ratios))))\n",
    "plt.xlabel('(α_general, α_domain)')\n",
    "plt.ylabel('Total Model Norm')\n",
    "plt.title('Multi-Delta Fusion: Effect of Mixing Ratios')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Multi-delta fusion allows combining capabilities from multiple sources!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Delta Analysis: Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between deltas\n",
    "similarities = param_delta.compute_cosine_similarity(\n",
    "    delta_general, \n",
    "    delta_domain,\n",
    "    layer_types=[\"overall\"]\n",
    ")\n",
    "\n",
    "print(f\"Cosine similarity between general and domain deltas: {similarities['overall']:.3f}\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Values close to 1: Deltas encode similar changes\")\n",
    "print(\"- Values close to 0: Deltas are orthogonal (independent)\")\n",
    "print(\"- Values close to -1: Deltas encode opposite changes\")\n",
    "\n",
    "# Create more deltas for visualization\n",
    "n_models = 6\n",
    "models = [create_model(seed=i) for i in range(n_models)]\n",
    "deltas = [param_delta.calculate_delta(m, theta_base) for m in models[1:]]\n",
    "\n",
    "# Compute pairwise similarities\n",
    "n_deltas = len(deltas)\n",
    "similarity_matrix = np.zeros((n_deltas, n_deltas))\n",
    "\n",
    "for i in range(n_deltas):\n",
    "    for j in range(n_deltas):\n",
    "        if i == j:\n",
    "            similarity_matrix[i, j] = 1.0\n",
    "        else:\n",
    "            sim = param_delta.compute_cosine_similarity(deltas[i], deltas[j])\n",
    "            similarity_matrix[i, j] = sim['overall']\n",
    "\n",
    "# Visualize similarity matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(similarity_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.colorbar(label='Cosine Similarity')\n",
    "plt.xlabel('Delta Index')\n",
    "plt.ylabel('Delta Index')\n",
    "plt.title('Pairwise Cosine Similarities Between Parameter Deltas')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Key Insights\n",
    "\n",
    "### ParamΔ Enables:\n",
    "1. **Zero-cost transfer** of post-training capabilities\n",
    "2. **Flexible scaling** with α parameter\n",
    "3. **Multi-source fusion** combining different capabilities\n",
    "4. **Orthogonal deltas** for independent knowledge\n",
    "\n",
    "### Use Cases:\n",
    "- Apply instruction-tuning to new base models instantly\n",
    "- Combine general and domain-specific capabilities\n",
    "- Transfer capabilities after continual pretraining\n",
    "- Experiment with different capability mixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Final demonstration: Complete workflow\nprint(\"Complete ParamΔ Workflow:\")\nprint(\"=\" * 50)\nprint(\"1. Load base and post-trained models\")\nprint(\"2. Compute delta: ΔΘ = Θ_post - Θ_base\")\nprint(\"3. Load new base model\")\nprint(\"4. Apply delta: Θ'_post = Θ'_base + ΔΘ\")\nprint(\"5. Enjoy post-trained capabilities with zero training!\")\nprint(\"=\" * 50)\nprint(\"\\nParamΔ: Post-training at the speed of inference!\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}